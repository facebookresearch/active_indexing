{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/home/pfz/anaconda3/envs/ssl_watermarking/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%cd ..\n",
    "\n",
    "import pickle, json, time, os, tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional\n",
    "\n",
    "import faiss\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "from PIL import Image\n",
    "import augly\n",
    "import augly.image as imaugs\n",
    "\n",
    "from scipy.special import betainc\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import beta\n",
    "from scipy.spatial.distance import cdist\n",
    "from skimage.metrics import structural_similarity, peak_signal_noise_ratio, hausdorff_distance\n",
    "\n",
    "import utils\n",
    "import data.augment_queries\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse R@1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = [{'attack': 'none', 'param0':0.0 }] \\\n",
    "    + [{'attack': 'contrast', 'param0': cf} for cf in [0.5, 2.0]] \\\n",
    "    + [{'attack': 'brightness', 'param0': bf} for bf in [0.5, 2.0]] \\\n",
    "    + [{'attack': 'hue', 'param0': 0.2}] \\\n",
    "    + [{'attack': 'blur', 'param0': 11}] \\\n",
    "    + [{'attack': 'jpeg', 'param0': 50}] \\\n",
    "    + [{'attack': 'rotation', 'param0': angle} for angle in [25,90]] \\\n",
    "    + [{'attack': 'center_crop', 'param0': 0.5}] \\\n",
    "    + [{'attack': 'resize', 'param0': 0.5}] \\\n",
    "    + [{'attack': 'meme_format', 'param0':0.0 }] \\\n",
    "    + [{'attack': 'auto', 'param0':0.0 }] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = [\"path/to/folder1/where/df/is/saved\", \"path/to/folder2/where/df/is/saved\"]\n",
    "dfs = {}\n",
    "for ii, path in enumerate(paths):\n",
    "    try:\n",
    "        csv_path = os.path.join(path, 'df.csv')\n",
    "        dfs[path] = pd.read_csv(csv_path, on_bad_lines='skip') \n",
    "        dfs[path] = dfs[path].fillna(0)\n",
    "    except:\n",
    "        print(f\"{path} is not found\")\n",
    "\n",
    "print([f\"{att['attack']}, {att['param0']}\" for att in attacks] + [\"avg, 0\"])\n",
    "for path in paths:\n",
    "    df = dfs[path]\n",
    "    df.drop(columns=['map', 'image', 'image_index', 'rank'], inplace=True)\n",
    "    df = df.groupby(['attack', 'param0'], as_index=False).mean()\n",
    "    df = df[df['attack']!='overlay_onto_screenshot']\n",
    "    r1s = [df[df['attack']==att['attack']][df['param0']==att['param0']]['r@1'].values[0] for att in attacks]\n",
    "    r1s.append(np.mean(r1s))\n",
    "    print(f\"{path} & {' & '.join([f'{r1:.2f}' for r1 in r1s])} \\\\\\\\\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse ICD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import PrecisionRecallDisplay\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Add ivfpq index\n",
    "dfs = {}\n",
    "paths = [\"path/to/folder1/where/icd_df/is/saved\", \"path/to/folder2/where/icd_df/is/saved\"]\n",
    "for ii, path in enumerate(paths):\n",
    "    try:\n",
    "        csv_path = os.path.join(path, 'icd_df.csv')\n",
    "        dfs[path] = pd.read_csv(csv_path, on_bad_lines='skip') \n",
    "        dfs[path][\"scores\"] = dfs[path][\"scores\"].apply(lambda row:[float(numb) for numb in row[1:-1].split()])\n",
    "        dfs[path][\"retrieved_ids\"] = dfs[path][\"retrieved_ids\"].apply(lambda row:[int(numb) for numb in row[1:-1].split()])\n",
    "        dfs[path] = dfs[path].fillna(0)\n",
    "    except:\n",
    "        print(f\"{path} is not found\")\n",
    "\n",
    "num_pair_per_query = 100\n",
    "\n",
    "_, ax = plt.subplots(figsize=(4,3))\n",
    "cmap = plt.get_cmap('tab10')\n",
    "colors = cmap.colors\n",
    "beta = 0.5\n",
    "for ii, path in enumerate(dfs.keys()):\n",
    "    print(path)\n",
    "    icd_df = dfs[path]\n",
    "\n",
    "    # build scores and ground truth\n",
    "    all_scores = icd_df[\"scores\"].values\n",
    "    all_ids = icd_df[\"image_index\"].values\n",
    "    all_retrieved_ids  = icd_df[\"retrieved_ids\"].values\n",
    "\n",
    "    # creating labels and score for the possible pairs\n",
    "    y_labels = []\n",
    "    y_scores = []\n",
    "    for ii in range(len(all_scores)):\n",
    "        scores = all_scores[ii][:num_pair_per_query] \n",
    "        retrieved_ids = all_retrieved_ids[ii][:num_pair_per_query]\n",
    "        if -1 in retrieved_ids:\n",
    "            idx = retrieved_ids.index(-1)\n",
    "            scores = scores[:idx]\n",
    "            retrieved_ids = retrieved_ids[:idx]\n",
    "        if True:\n",
    "            scores = [-score for score in scores]\n",
    "            labels = [0 if all_ids[ii] != id else 1 for id in retrieved_ids]\n",
    "        else: # potential score normalization\n",
    "            scores = [-scores[jj]+beta*(scores[jj+1]) for jj in range(len(scores)-1)]\n",
    "            labels = [0 if all_ids[ii] != id else 1 for id in retrieved_ids[:-1]]\n",
    "        if icd_df['image'][ii]<10000 and np.sum(labels) == 0:\n",
    "            # if the true match is never returned, we add it with a high distance (low score)\n",
    "            # this allows us to be fair in the case of the IVF, where the true match can sometimes be missing\n",
    "            scores.append(-3)\n",
    "            labels.append(1)\n",
    "        y_labels += labels\n",
    "        y_scores += scores\n",
    "\n",
    "    # compute precision recall curve\n",
    "    precision = dict()\n",
    "    recall = dict()\n",
    "    average_precision = dict()\n",
    "    precision, recall, _ = precision_recall_curve(y_labels, y_scores, pos_label=1)\n",
    "    average_precision = average_precision_score(y_labels, y_scores, pos_label=1)\n",
    "    display = PrecisionRecallDisplay(\n",
    "        recall=recall,\n",
    "        precision=precision\n",
    "    )\n",
    "    name = path\n",
    "    name += \" (\" + r'$\\mu$AP={:.3f}'.format(average_precision) + \" )\"\n",
    "    display.plot(ax=ax, name=name)\n",
    "\n",
    "ax.set_xlim(0, 0.5)\n",
    "\n",
    "ax.legend(loc=\"upper right\", bbox_to_anchor=(1.0, 0.95),  framealpha=0.6, frameon=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proba of failure of the IVF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> Building backbone...')\n",
    "model_path = \"path/to/sscd/sscd_disc_mixup.torchscript.pt\"\n",
    "model = utils.build_backbone(path=model_path, name='custom')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "size= 288\n",
    "print('>>> Building Index...')\n",
    "idx_path = \"path/to/idx=IVF4096,PQ8x8_quant=L2.index\"\n",
    "index = faiss.read_index(idx_path)\n",
    "ivf_centroids = index.quantizer.reconstruct_n(0, index.nlist)\n",
    "n_total = index.ntotal\n",
    "\n",
    "fts = torch.load(\"path/to/ref1M/fts.pth\")\n",
    "index.add(fts.detach().cpu().numpy())\n",
    "index.make_direct_map()\n",
    "img_dir_pas = \"path/to/passive/imgs/dir\"\n",
    "img_dir_act = \"path/to/activated/imgs/dir\"\n",
    "\n",
    "default_transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), transforms.Resize((size,size))])\n",
    "\n",
    "def get_centroids(img_dir, augment=True, nmax=100):\n",
    "    data_loader = utils.get_dataloader(img_dir, transform=None, batch_size=1, shuffle=False)\n",
    "    rng = np.random.RandomState(0)\n",
    "    centroids = []\n",
    "    for ii, img in enumerate(tqdm.tqdm(data_loader)):\n",
    "        pil_img = img[0]\n",
    "        if augment:\n",
    "            attacked_img, aug_params = augment_queries.augment_img(pil_img, rng, return_params=True)\n",
    "        else:\n",
    "            attacked_img = pil_img\n",
    "        attacked_img = default_transform(attacked_img).unsqueeze(0).to(device)\n",
    "        ft = model(attacked_img)\n",
    "        ft = ft.detach().cpu().numpy()\n",
    "\n",
    "        ivf_D, ivf_I = index.quantizer.search(ft, k=1)\n",
    "        centroids.append(ivf_I[0][0])\n",
    "\n",
    "        if ii >= nmax:\n",
    "            break\n",
    "    return centroids\n",
    "\n",
    "centroids_pas = get_centroids(img_dir_pas, augment=True, nmax=10000)\n",
    "centroids_act = get_centroids(img_dir_act, augment=True, nmax=10000)\n",
    "centroids_gt = get_centroids(img_dir_pas, augment=False, nmax=10000)\n",
    "print('pf_ivf : ', np.mean([el1 ==el2 for el1, el2 in zip(centroids_pas, centroids_gt)]))\n",
    "print('pf_ivf : ', np.mean([el1 ==el2 for el1, el2 in zip(centroids_act, centroids_gt)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('>>> Building backbone...')\n",
    "model_path = \"path/to/sscd/sscd_disc_mixup.torchscript.pt\"\n",
    "model = utils.build_backbone(path=model_path, name='custom')\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "size= 288\n",
    "print('>>> Building Index...')\n",
    "idx_path = \"path/to/idx=IVF4096,PQ8x8_quant=L2.index\"\n",
    "index = faiss.read_index(idx_path)\n",
    "ivf_centroids = index.quantizer.reconstruct_n(0, index.nlist)\n",
    "n_total = index.ntotal\n",
    "\n",
    "fts = torch.load(\"path/to/ref1M/fts.pth\")\n",
    "index.add(fts.detach().cpu().numpy())\n",
    "index.make_direct_map()\n",
    "def get_dists(img_dir, transform, n_max = 1000):\n",
    "    dists_1 = []\n",
    "    dists_2 = []\n",
    "    ct=0\n",
    "    default_transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "    for img_name in tqdm.tqdm(os.listdir(img_dir)):\n",
    "        img_path = os.path.join(img_dir, img_name)\n",
    "        if 'attack' in img_name:\n",
    "            continue\n",
    "        pil_img = Image.open(img_path)\n",
    "        img = transform(pil_img).unsqueeze(0).to(device)\n",
    "        img = functional.resize(img, (size,size))\n",
    "        \n",
    "        # create ft and add\n",
    "        ft = model(img).detach().cpu().numpy()\n",
    "        if index.ntotal < n_total + n_max:\n",
    "            index.add(ft)\n",
    "            index.make_direct_map()\n",
    "\n",
    "        img = default_transform(pil_img).unsqueeze(0).to(device)\n",
    "        img = functional.resize(img, (size,size))\n",
    "        ft_ori = model(img).detach().cpu().numpy()\n",
    "\n",
    "        # recons\n",
    "        pq_recons = index.reconstruct(n_total+ct)\n",
    "        dist = np.linalg.norm(ft-pq_recons)\n",
    "        dists_1.append(dist)\n",
    "\n",
    "        # cluster\n",
    "        ivf_D, ivf_I = index.quantizer.search(ft_ori, k=1)\n",
    "        centroid = ivf_centroids.take(ivf_I.flatten(), axis=0)\n",
    "        dist = np.linalg.norm(ft-centroid)\n",
    "        dists_2.append(dist)\n",
    "\n",
    "        ct += 1\n",
    "        if ct >= n_max:\n",
    "            break\n",
    "    return np.array(dists_1), np.array(dists_2)\n",
    "    \n",
    "n_max = 10000\n",
    "\n",
    "print('>>> Computing distances...')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "img_dir_pas = \"path/to/passive/imgs/dir\"\n",
    "img_dir_act = \"path/to/activated/imgs/dir\"\n",
    "\n",
    "dists_ref, dists_ivf_ref = get_dists(img_dir_pas,transform, n_max=n_max)\n",
    "dists_act, dists_ivf_act= get_dists(img_dir_act,transform, n_max=n_max)\n",
    "\n",
    "print('>>> Computing distances for with hue shift...')\n",
    "transform = transforms.Compose([\n",
    "    lambda x: functional.adjust_contrast(x, 2.0),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "t_dists_ref, t_dists_ivf_ref = get_dists(img_dir_pas,transform, n_max=n_max)\n",
    "t_dists_act, t_dists_ivf_act= get_dists(img_dir_act,transform, n_max=n_max)\n",
    "\n",
    "\n",
    "def get_dists_nonmatching(data_loader, n_max = 100):\n",
    "    ct=0\n",
    "    fts = []\n",
    "    pqs = []\n",
    "    for img in tqdm.tqdm(data_loader):\n",
    "        img = img.to(device)\n",
    "        ft = model(img).detach().cpu().numpy()\n",
    "        fts.append(ft)\n",
    "        ct += ft.shape[0]\n",
    "        if ct >= n_max:\n",
    "            break\n",
    "    fts = np.concatenate(fts, axis=0)\n",
    "    pq_recons = index.reconstruct_n(0, n_max)\n",
    "    dists = cdist(fts, pq_recons, metric='euclidean')\n",
    "    dists = dists[~np.eye(dists.shape[0],dtype=bool)].reshape(dists.shape[0],-1)\n",
    "    return dists.flatten()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    transforms.Resize((size,size)),\n",
    "    ])\n",
    "\n",
    "data_loader = utils.get_dataloader(img_dir_pas, transform, batch_size=128, collate_fn=None)\n",
    "dists_nonmatching = get_dists_nonmatching(data_loader, n_max = 128)\n",
    "\n",
    "data_loader = utils.get_dataloader(img_dir_act, transform, batch_size=128, collate_fn=None)\n",
    "dists_nonmatching_act = get_dists_nonmatching(data_loader, n_max = 128)\n",
    "\n",
    "dists_ref = np.array(dists_ref)\n",
    "print(np.mean(dists_ref**2), np.std(dists_ref**2))\n",
    "t_dists_ref = np.array(t_dists_ref)\n",
    "print(np.mean(t_dists_ref**2), np.std(t_dists_ref**2))\n",
    "dists_act = np.array(dists_act)\n",
    "print(np.mean(dists_act**2), np.std(dists_act**2))\n",
    "t_dists_act = np.array(t_dists_act)\n",
    "print(np.mean(t_dists_act**2), np.std(t_dists_act**2))\n",
    "dists_nonmatching = np.array(dists_nonmatching)\n",
    "print(np.mean(dists_nonmatching**2), np.std(dists_nonmatching**2))\n",
    "dists_nonmatching_act = np.array(dists_nonmatching_act)\n",
    "print(np.mean(dists_nonmatching_act**2), np.std(dists_nonmatching_act**2))\n",
    "dists_ref = np.array(dists_ref)**2\n",
    "t_dists_ref = np.array(t_dists_ref)**2\n",
    "dists_act = np.array(dists_act)**2\n",
    "t_dists_act = np.array(t_dists_act)**2\n",
    "dists_nonmatching = np.array(dists_nonmatching)**2\n",
    "dists_nonmatching_act = np.array(dists_nonmatching_act)**2\n",
    "import scipy.stats as stats\n",
    "plt.rc('text', usetex=False)\n",
    "\n",
    "cmap = plt.get_cmap('tab10')\n",
    "colors = cmap.colors\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(4, 3.5), sharex=True, sharey=True)\n",
    "\n",
    "axs[0].axvline(dists_ref.mean(), linestyle='dashed', linewidth=1, color=colors[0], alpha=0.8)\n",
    "axs[0].axvline(t_dists_ref.mean(), linestyle='dashed', linewidth=1, color=colors[1], alpha=0.8)\n",
    "axs[0].axvline(dists_nonmatching.mean(), linestyle='dashed', linewidth=1, color=colors[2], alpha=0.8)\n",
    "axs[0].hist(dists_nonmatching, bins=100, label=r'$||y-q(x)||^2$', density=True, color=colors[2], alpha=0.4)\n",
    "axs[0].hist(dists_ref, bins=100, label=r'$||x-q(x)||^2$', density=True, color=colors[0], alpha=0.8)\n",
    "axs[0].hist(t_dists_ref, bins=100, label=r'$||\\hat{x}-q(x)||^2$', density=True, color=colors[1], alpha=0.8)\n",
    "axs[0].set_title('Passive')\n",
    "\n",
    "axs[1].axvline(dists_ref.mean(), linestyle='dashed', linewidth=1, color=colors[0], alpha=0.2)\n",
    "axs[1].axvline(t_dists_ref.mean(), linestyle='dashed', linewidth=1, color=colors[1], alpha=0.2)\n",
    "axs[1].axvline(dists_act.mean(), linestyle='dashed', linewidth=1, color=colors[0], alpha=0.8)\n",
    "axs[1].axvline(t_dists_act.mean(), linestyle='dashed', linewidth=1, color=colors[1], alpha=0.8)\n",
    "axs[1].axvline(dists_nonmatching_act.mean(), linestyle='dashed', linewidth=1, color=colors[2], alpha=0.8)\n",
    "axs[1].hist(dists_nonmatching_act, bins=100, label=r'$||y^\\star-q(x)||^2$', density=True, color=colors[2], alpha=0.4)\n",
    "axs[1].hist(dists_act, bins=100, label=r'$||x^\\star-q(x)||^2$', density=True, color=colors[0], alpha=0.8)\n",
    "axs[1].hist(t_dists_act, bins=100, label=r'$||\\hat{x}^\\star-q(x)||^2$', density=True, color=colors[1], alpha=0.8)\n",
    "axs[1].set_title('Active')\n",
    "\n",
    "axs[0].legend(framealpha=0.6, frameon=True, loc='upper left')\n",
    "axs[1].legend(framealpha=0.6, frameon=True, loc='upper right')\n",
    "axs[0].grid()\n",
    "axs[1].grid()\n",
    "plt.tight_layout()\n",
    "plt.yticks([])\n",
    "plt.xlim(0.5,1.4)\n",
    "plt.show()\n",
    "print(dists_ref.mean(), t_dists_ref.mean(), dists_act.mean(), t_dists_act.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_times(idx_path, nqueries=10000):\n",
    "    print(idx_path)\n",
    "    index = faiss.read_index(idx_path)\n",
    "    fts_reference_path = \"path/to/ref_1M/fts.pth\"\n",
    "    fts = torch.load(fts_reference_path)\n",
    "    index.add(fts.detach().cpu().numpy())\n",
    "    n_index_ref = index.ntotal\n",
    "    if 'IVF' in idx_path:\n",
    "        index.make_direct_map()\n",
    "\n",
    "    np.random.seed(0)\n",
    "    fts = np.random.randn(nqueries, 512).astype(np.float32)\n",
    "\n",
    "    nprobes = [1,16,32]\n",
    "    if not 'IVF' in idx_path:\n",
    "        nprobes = [1]\n",
    "\n",
    "    for nprobe in nprobes:\n",
    "        index.nprobe = nprobe\n",
    "        search_times = []\n",
    "        for ii in range(nqueries):\n",
    "            ft = fts[ii:ii+1]\n",
    "            time_0 = time.time()\n",
    "            index.search(ft, k=1)\n",
    "            search_times.append(time.time() - time_0)\n",
    "        search_times = 1e3 * np.array(search_times)\n",
    "        print(f'Averaged search time: {np.mean(search_times)} - Max: {np.max(search_times)} - Min: {np.min(search_times)} - Std: {np.std(search_times)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_times(\"path/to/index.index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def psnr(x):\n",
    "    return 20*np.log10(255) - 10*np.log10(np.mean(x**2))\n",
    "\n",
    "def visu_diff(img_ori, img_comp, title=None, figsize=(20,30), crop=None, hori=True):\n",
    "    plt.figure(figsize=figsize)\n",
    "    if title is not None:\n",
    "        plt.suptitle(title, fontsize=16)\n",
    "        \n",
    "    img_ori_ar = np.asarray(img_ori)\n",
    "    img_comp_ar = np.asarray(img_comp)\n",
    "\n",
    "    if hori:\n",
    "        plt.subplot(1, 3, 1)    \n",
    "    else:\n",
    "        plt.subplot(3, 1, 1)\n",
    "    plt.imshow(img_ori_ar)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image 1')\n",
    "\n",
    "    if hori:\n",
    "        plt.subplot(1, 3, 2)    \n",
    "    else:\n",
    "        plt.subplot(3, 1, 2)\n",
    "    plt.imshow(img_comp_ar)\n",
    "    plt.axis('off')\n",
    "    plt.title('Image 2')\n",
    "\n",
    "    diff = img_comp_ar.astype(int)-img_ori_ar.astype(int)\n",
    "    print(\"Linf = %i\" %np.amax(np.abs(diff)), ' at ', np.unravel_index(np.argmax(np.abs(diff), axis=None), np.abs(diff).shape))\n",
    "    print(\"PSNR = %f\" %psnr(diff))\n",
    "    diff = np.linalg.norm(diff, ord=1, axis=2)\n",
    "    if hori:\n",
    "        plt.subplot(1, 3, 3)    \n",
    "    else:\n",
    "        plt.subplot(3, 1, 3)\n",
    "    plt.imshow(diff)\n",
    "    plt.title('Difference')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.axis('off')\n",
    "    plt.grid(False)\n",
    "    plt.show()\n",
    "\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_img_dir = \"path/to/original/img/dir\"\n",
    "img_dir = \"path/to/activated/img/dir\"\n",
    "\n",
    "filenames = os.listdir(ori_img_dir)\n",
    "filenames.sort()\n",
    "psnrs = []\n",
    "ssims = []\n",
    "linfs = []\n",
    "for ii, filename in enumerate(filenames):\n",
    "    if ii > 1000:\n",
    "        break\n",
    "    pil_img_ori = Image.open(os.path.join(ori_img_dir, filename))\n",
    "    pil_img = Image.open(os.path.join(img_dir, f'{ii:05d}.png'))\n",
    "    img_ori = np.asarray(pil_img_ori)\n",
    "    img = np.asarray(pil_img)\n",
    "    print(img_ori.shape, img.shape, filename, f'{ii:05d}.png')\n",
    "    ssims.append(structural_similarity(img_ori, img, channel_axis=2))\n",
    "    psnrs.append(peak_signal_noise_ratio(img_ori, img))\n",
    "    linfs.append(np.amax(np.abs(img_ori.astype(int)-img.astype(int))))\n",
    "    if ssims[-1]<0.9:\n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssim_mean, ssim_std, ssim_max, ssim_min = np.mean(ssims), np.std(ssims), np.max(ssims), np.min(ssims) \n",
    "psnr_mean, psnr_std, psnr_max, psnr_min = np.mean(psnrs), np.std(psnrs), np.max(psnrs), np.min(psnrs)\n",
    "linf_mean, linf_std, linf_max, linf_min = np.mean(linfs), np.std(linfs), np.max(linfs), np.min(linfs)\n",
    "print(f\"SSIM: {ssim_mean:.4f}±{ssim_std:.4f} [{ssim_min:.4f}, {ssim_max:.4f}]\")\n",
    "print(f\"PSNR: {psnr_mean:.4f}±{psnr_std:.4f} [{psnr_min:.4f}, {psnr_max:.4f}]\")\n",
    "print(f\"Linf: {linf_mean:.4f}±{linf_std:.4f} [{linf_min:.4f}, {linf_max:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('ssl_watermarking': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca1cf4d29d3f2b5143ded1ea4227ed45726976b59f5f3aa2311ff36ca991fa59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
